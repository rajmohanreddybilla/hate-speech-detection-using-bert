{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHT2XHcpMVYO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the training data\n",
        "df = pd.read_csv(\"/content/drive/My Drive/DL/train.csv\")\n",
        "\n",
        "# Show first 5 rows\n",
        "print(\"First 5 rows:\")\n",
        "display(df.head())\n",
        "\n",
        "# Show columns\n",
        "print(\"\\nColumns in the dataset:\")\n",
        "print(df.columns)\n",
        "\n",
        "# Show dataset info\n",
        "print(\"\\nDataset info:\")\n",
        "print(df.info())\n",
        "\n",
        "# Number of rows\n",
        "print(\"\\nNumber of rows:\", len(df))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a binary label: toxic OR not toxic\n",
        "df[\"toxic_binary\"] = df[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].max(axis=1)\n",
        "\n",
        "# Check the first few rows\n",
        "df[[\"comment_text\", \"toxic_binary\"]].head()"
      ],
      "metadata": {
        "id": "tS7zqbIzMce_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df[\"comment_text\"].values,\n",
        "    df[\"toxic_binary\"].values,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training samples:\", len(train_texts))\n",
        "print(\"Testing samples:\", len(test_texts))"
      ],
      "metadata": {
        "id": "ujSQoO1fMgSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Test the tokenizer on one example\n",
        "test_text = \"You are an idiot.\"\n",
        "tokens = tokenizer.tokenize(test_text)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(\"Tokens:\", tokens)\n",
        "print(\"Token IDs:\", ids)"
      ],
      "metadata": {
        "id": "DC5Gjw8_Mi3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ToxicCommentsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Tokenize the text\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "RNsaFtfvMoWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = ToxicCommentsDataset(train_texts, train_labels, tokenizer)[0]\n",
        "sample"
      ],
      "metadata": {
        "id": "WQc-aylYMrwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create dataset objects\n",
        "train_dataset = ToxicCommentsDataset(train_texts, train_labels, tokenizer, max_len=128)\n",
        "test_dataset = ToxicCommentsDataset(test_texts, test_labels, tokenizer, max_len=128)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "print(\"Train loader batches:\", len(train_loader))\n",
        "print(\"Test loader batches:\", len(test_loader))"
      ],
      "metadata": {
        "id": "WJv07pWyMu9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Load BERT with a classification head\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=2\n",
        ")\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "device"
      ],
      "metadata": {
        "id": "-yHVLWjUMy24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "0i7pXBA3M2Xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm  # Progress bar\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Training loop\n",
        "epochs = 2  # You can increase to 3 if needed\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Move data to GPU\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Average training loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "id": "GV4upd4FM60k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import torch\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "# Disable gradient calculation for evaluation\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask\n",
        "        )\n",
        "\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds)\n",
        "recall = recall_score(all_labels, all_preds)\n",
        "f1 = f1_score(all_labels, all_preds)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "id": "0Db2xvhrM-tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"Non-Toxic\", \"Toxic\"],\n",
        "            yticklabels=[\"Non-Toxic\", \"Toxic\"])\n",
        "\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "cm"
      ],
      "metadata": {
        "id": "g1jxF909NCe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "\n",
        "model_path = \"/content/drive/My Drive/DL/bert_toxic_model\"\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Move model to GPU if available\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "T5Qm9mg1NG0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def predict_toxicity(text):\n",
        "    model.eval()\n",
        "\n",
        "    encoding = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        max_length=128,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probs = F.softmax(logits, dim=1)\n",
        "        predicted_class = torch.argmax(probs, dim=1).item()\n",
        "        probability = probs[0][predicted_class].item()\n",
        "\n",
        "    label = \"Toxic\" if predicted_class == 1 else \"Not Toxic\"\n",
        "    return label, probability"
      ],
      "metadata": {
        "id": "QShDXu8ONKir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_toxicity(\"I hate you, you stupid idiot!\"))\n",
        "print(predict_toxicity(\"You are an amazing person, have a great day!\"))\n",
        "print(predict_toxicity(\"Shut up, you clown.\"))\n",
        "print(predict_toxicity(\"I like like you, i hate you\"))"
      ],
      "metadata": {
        "id": "C5cOteTPNQPf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}